---
title: "æ¬¢è¿ä½¿ç”¨Llama 3.2ï¼Œç°åœ¨Llamaå¯ä»¥åœ¨æ‚¨çš„è®¾å¤‡ä¸ŠæŸ¥çœ‹å’Œè¿è¡Œäº†" 
thumbnail: /blog/assets/llama32/thumbnail.jpg
authors:
- user: merve
- user: philschmid
- user: osanseviero
- user: reach-vb
- user: lewtun
- user: ariG23498
- user: pcuenq
translators:
- user: roseking
---

# æ¬¢è¿ä½¿ç”¨Llama 3.2ï¼Œç°åœ¨Llamaå¯ä»¥åœ¨æ‚¨çš„è®¾å¤‡ä¸ŠæŸ¥çœ‹å’Œè¿è¡Œäº†

Llama 3.2 æ¥äº†ï¼ä»Šå¤©ï¼Œæˆ‘ä»¬æ¬¢è¿ Llama ç³»åˆ—çš„ä¸‹ä¸€ä¸ªç‰ˆæœ¬åŠ å…¥ Hugging Faceã€‚è¿™æ¬¡ï¼Œæˆ‘ä»¬å¾ˆé«˜å…´ä¸ Meta åˆä½œå‘å¸ƒå¤šæ¨¡æ€å’Œå°å‹æ¨¡å‹ã€‚åœ¨ Hub ä¸Šæä¾›äº†åä¸ªå¼€æºæ¨¡å‹ï¼ˆ5 ä¸ªå¤šæ¨¡æ€æ¨¡å‹å’Œ 5 ä¸ªä»…æ–‡æœ¬æ¨¡å‹ï¼‰ã€‚

Llama 3.2 Vision æœ‰ä¸¤ç§å°ºå¯¸ï¼š11B é€‚ç”¨äºåœ¨æ¶ˆè´¹çº§ GPU ä¸Šçš„é«˜æ•ˆéƒ¨ç½²å’Œå¼€å‘ï¼Œ90B é€‚ç”¨äºå¤§è§„æ¨¡åº”ç”¨ã€‚ä¸¤ç§ç‰ˆæœ¬éƒ½æœ‰åŸºç¡€ç‰ˆå’ŒæŒ‡ä»¤å¾®è°ƒç‰ˆã€‚é™¤äº†è¿™å››ä¸ªå¤šæ¨¡æ€æ¨¡å‹å¤–ï¼ŒMeta è¿˜å‘å¸ƒäº†æ”¯æŒè§†è§‰çš„æ–°ç‰ˆ Llama Guardã€‚Llama Guard 3 æ˜¯ä¸€ä¸ªå®‰å…¨æ¨¡å‹ï¼Œå¯ä»¥åˆ†ç±»æ¨¡å‹è¾“å…¥å’Œç”Ÿæˆå†…å®¹ï¼ŒåŒ…æ‹¬æ£€æµ‹æœ‰å®³çš„å¤šæ¨¡æ€æç¤ºæˆ–åŠ©æ‰‹å“åº”ã€‚

Llama 3.2 è¿˜åŒ…æ‹¬å¯ä»¥åœ¨è®¾å¤‡ä¸Šè¿è¡Œçš„å°å‹ä»…æ–‡æœ¬è¯­è¨€æ¨¡å‹ã€‚å®ƒä»¬æœ‰ä¸¤ç§æ–°å°ºå¯¸ï¼ˆ1B å’Œ 3Bï¼‰ï¼Œæœ‰åŸºç¡€ç‰ˆå’ŒæŒ‡ä»¤ç‰ˆï¼Œå¹¶ä¸”åœ¨å®ƒä»¬çš„å¤§å°èŒƒå›´å†…å…·æœ‰å¼ºå¤§çš„èƒ½åŠ›ã€‚è¿˜æœ‰ä¸€ä¸ªå°å‹ 1B ç‰ˆæœ¬çš„ Llama Guardï¼Œå¯ä»¥åœ¨ç”Ÿäº§ç”¨ä¾‹ä¸­ä¸è¿™äº›æˆ–æ›´å¤§çš„æ–‡æœ¬æ¨¡å‹ä¸€èµ·éƒ¨ç½²ã€‚

åœ¨å‘å¸ƒçš„åŠŸèƒ½å’Œé›†æˆä¸­ï¼Œæˆ‘ä»¬æœ‰ï¼š
- [Hub ä¸Šçš„æ¨¡å‹æ£€æŸ¥ç‚¹](https://huggingface.co/collections/meta-llama/llama-32-66f448ffc8c32f949b04c8cf)
- Hugging Face Transformers å’Œ TGI é›†æˆç”¨äº Vision æ¨¡å‹
- ä¸ Inference Endpointsã€Google Cloudã€Amazon SageMaker å’Œ DELL Enterprise Hub çš„æ¨ç†ä¸éƒ¨ç½²é›†æˆ
- ä½¿ç”¨ [transformersğŸ¤—](https://github.com/huggingface/huggingface-llama-recipes/tree/main/Llama-Vision FT.ipynb) å’Œ [TRL](https://github.com/huggingface/trl/tree/main/examples/scripts/sft_vlm.py) åœ¨å•ä¸ª GPU ä¸Šå¾®è°ƒ Llama 3.2 11B Vision

## ç›®å½•

- [ä»€ä¹ˆæ˜¯ Llama 3.2 Visionï¼Ÿ](#what-is-llama-32-vision)
- [Llama 3.2 è®¸å¯è¯å˜æ›´ã€‚å¯¹ä¸èµ·ï¼Œæ¬§ç›Ÿ :(](#llama-32-license-changes-sorry-eu-)
- [Llama 3.2 1B å’Œ 3B æœ‰ä»€ä¹ˆç‰¹åˆ«ä¹‹å¤„ï¼Ÿ](#what-is-special-about-llama-32-1b-and-3b)
- [æ¼”ç¤º](#demo)
- [ä½¿ç”¨ Hugging Face Transformers](#using-hugging-face-transformers)
- [Llama 3.2 1B & 3B è¯­è¨€æ¨¡å‹](#llama-32-1b--3b-language-models)
- [Llama 3.2 Vision](#llama-32-vision)
- [è®¾å¤‡ä¸Šè¿è¡Œ](#on-device)
- [Llama.cpp & Llama-cpp-python](#llamacpp--llama-cpp-python)
- [Transformers.js](#transformersjs)
- [å¾®è°ƒ Llama 3.2](#fine-tuning-llama-32)
- [Hugging Face åˆä½œä¼™ä¼´é›†æˆ](#hugging-face-partner-integrations)
- [å…¶ä»–èµ„æº](#additional-resources)
- [è‡´è°¢](#acknowledgements)

## ä»€ä¹ˆæ˜¯ Llama 3.2 Visionï¼Ÿ

Llama 3.2 Vision æ˜¯ Meta å‘å¸ƒçš„æœ€å¼ºå¤§çš„å¼€æºå¤šæ¨¡æ€æ¨¡å‹ã€‚å®ƒå…·æœ‰å‡ºè‰²çš„è§†è§‰ç†è§£å’Œæ¨ç†èƒ½åŠ›ï¼Œå¯ä»¥ç”¨äºå®Œæˆå„ç§ä»»åŠ¡ï¼ŒåŒ…æ‹¬è§†è§‰æ¨ç†å’Œå®šä½ã€æ–‡æ¡£é—®ç­”å’Œå›¾æ–‡æ£€ç´¢ã€‚æ€ç»´é“¾ï¼ˆChain of Thought, CoTï¼‰ç­”æ¡ˆé€šå¸¸éå¸¸å¥½ï¼Œè¿™ä½¿å¾—è§†è§‰æ¨ç†ç‰¹åˆ«å¼ºå¤§ã€‚

Llama 3.2 Vision å¯ä»¥å¤„ç†æ–‡æœ¬å’Œå›¾åƒï¼Œä¹Ÿå¯ä»¥ä»…å¤„ç†æ–‡æœ¬ã€‚é€šè¿‡å›¾æ–‡æç¤ºï¼Œæ¨¡å‹å¯ä»¥æ¥å—è‹±æ–‡è¾“å…¥ï¼Œè€Œå¯¹äºä»…æ–‡æœ¬æç¤ºï¼Œæ¨¡å‹å¯ä»¥å¤„ç†å¤šç§è¯­è¨€ã€‚ä»…æ–‡æœ¬æ¨¡å¼æ”¯æŒçš„è¯­è¨€åŒ…æ‹¬è‹±è¯­ã€å¾·è¯­ã€æ³•è¯­ã€æ„å¤§åˆ©è¯­ã€è‘¡è„ç‰™è¯­ã€å°åœ°è¯­ã€è¥¿ç­ç‰™è¯­å’Œæ³°è¯­ã€‚

è¿™äº›æ¨¡å‹çš„æ¶æ„åŸºäº Llama 3.1 LLM ä¸è§†è§‰å¡”å’Œå›¾åƒé€‚é…å™¨çš„ç»“åˆã€‚ä½¿ç”¨çš„æ–‡æœ¬æ¨¡å‹æ˜¯ Llama 3.1 8B ç”¨äº Llama 3.2 11B Vision æ¨¡å‹ï¼ŒLlama 3.1 70B ç”¨äº 3.2 90B Vision æ¨¡å‹ã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œåœ¨è§†è§‰æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ–‡æœ¬æ¨¡å‹è¢«å†»ç»“ä»¥ä¿ç•™ä»…æ–‡æœ¬æ€§èƒ½ã€‚

ä¸‹é¢ä½ å¯ä»¥æ‰¾åˆ°ä¸€äº›æ¥è‡ª 11B æŒ‡ä»¤å¾®è°ƒæ¨¡å‹çš„æ¨ç†ç¤ºä¾‹ï¼Œå±•ç¤ºäº†çœŸå®ä¸–ç•ŒçŸ¥è¯†ã€æ–‡æ¡£æ¨ç†å’Œä¿¡æ¯å›¾ç†è§£èƒ½åŠ›ã€‚

| å›¾åƒ | æè¿° |
|------|------|
| ![Wat Arun](https://huggingface.co/datasets/huggingface/release-assets/resolve/main/wat_arun.jpg) | **è¿™å¼ å›¾ç‰‡ä½äºå“ªé‡Œï¼Ÿé™„è¿‘æœ‰å“ªäº›å…¶ä»–æ™¯ç‚¹ï¼Ÿ**<br>è¿™å¼ å›¾ç‰‡æç»˜äº†æ³°å›½æ›¼è°·çš„å¤§çš‡å®«ã€‚å¤§çš‡å®«æ˜¯ä¸€ä¸ªå»ºç­‘ç¾¤ï¼Œæ›¾ä½œä¸ºæš¹ç½—å›½ç‹çš„å®˜æ–¹ä½æ‰€å’Œæ”¿åºœè¡Œæ”¿ä¸­å¿ƒé•¿è¾¾ 150 å¹´ã€‚å®ƒæ˜¯æ›¼è°·æœ€å—æ¬¢è¿çš„æ—…æ¸¸æ™¯ç‚¹ä¹‹ä¸€ï¼Œæ˜¯ä»»ä½•è®¿é—®è¯¥åŸå¸‚çš„æ¸¸å®¢å¿…çœ‹çš„åœ°æ–¹ã€‚<br><br>å¤§çš‡å®«é™„è¿‘çš„ä¸€äº›æ™¯ç‚¹åŒ…æ‹¬ï¼š<br>* ç‰ä½›å¯ºï¼šè¿™åº§å¯ºåº™ä½äºå¤§çš‡å®«å»ºç­‘ç¾¤å†…ï¼Œæ˜¯è‘—åçš„ç¿¡ç¿ ä½›åƒçš„æ‰€åœ¨åœ°ã€‚<br>* å§ä½›å¯ºï¼šè¿™åº§å¯ºåº™ä½äºå¤§çš‡å®«é™„è¿‘ï¼Œæ˜¯å·¨å¤§çš„å§ä½›é›•åƒçš„æ‰€åœ¨åœ°ã€‚<br>* éš†æŠ«å°¼å…¬å›­ï¼šè¿™ä¸ªå…¬å›­ä½äºæ›¼è°·å¸‚ä¸­å¿ƒï¼Œä¸ºåŸå¸‚æä¾›äº†ä¸€ä¸ªå®é™çš„é¿é£æ¸¯ã€‚<br>* å‰å§†Â·æ±¤æ™®æ£®ä¹‹å®¶ï¼šè¿™ä¸ªåšç‰©é¦†å±•ç¤ºäº†å‰å§†Â·æ±¤æ™®æ£®çš„ç”Ÿæ´»å’Œå·¥ä½œï¼Œä»–æ˜¯ç¾å›½å•†äººï¼Œåœ¨ 1950 å¹´ä»£å’Œ 1960 å¹´ä»£å¸®åŠ©æŒ¯å…´äº†æ³°å›½çš„ä¸ç»¸äº§ä¸šã€‚ |
| ![Weather Events](https://huggingface.co/datasets/huggingface/release-assets/resolve/main/weather_events.png) | **æ ¹æ®è¿™å¼ å›¾ï¼Œå¹²æ—±å‘ç”Ÿåœ¨å“ªé‡Œï¼Ÿ**<br>**2016 å¹´å¹²æ—±åœ°åŒº**<br>æ ¹æ®è¿™å¼ å›¾ï¼Œ2016 å¹´å¹²æ—±å‘ç”Ÿåœ¨ä¸¤ä¸ªä¸åŒçš„åœ°åŒºï¼š<br>* **ä¸œéå’Œå—éƒ¨éæ´²**ï¼šè¿™ä¸ªåœ°åŒºç»å†äº†ä¸¥é‡çš„å¹²æ—±ã€‚<br>* **æ™ºåˆ©**ï¼šæ™ºåˆ©åœ¨ 1 æœˆä»½ç»å†äº† 50 å¤šå¹´æ¥æœ€å¹²ç‡¥çš„å¤©æ°”ã€‚è¿™äº›åœ°åŒºåœ¨é‚£ä¸ªæ—¶æœŸé¢ä¸´ä¸¥é‡çš„æ°´èµ„æºçŸ­ç¼ºé—®é¢˜ã€‚ |
| ![Invoice](https://huggingface.co/datasets/huggingface/release-assets/resolve/main/invoice.png) | **ä»å‘ç¥¨æ—¥æœŸåˆ°æˆªæ­¢æ—¥æœŸéœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿç®€çŸ­æ˜äº†ã€‚**<br>**å‘ç¥¨æ—¥æœŸï¼š** 2019 å¹´ 2 æœˆ 11 æ—¥<br>**æˆªæ­¢æ—¥æœŸï¼š** 2019 å¹´ 2 æœˆ 26 æ—¥<br>**æ—¶é—´å·®è®¡ç®—ï¼š**<br>2019 å¹´ 2 æœˆ 26 æ—¥ - 2019 å¹´ 2 æœˆ 11 æ—¥ = 15 å¤©<br><br>å‘ç¥¨æ—¥æœŸå’Œæˆªæ­¢æ—¥æœŸä¹‹é—´çš„æ—¶é—´å·®æ˜¯ **15 å¤©ã€‚** |

Vision æ¨¡å‹å…·æœ‰ 128k ä¸ª token çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œè¿™å…è®¸åŒ…å«å›¾åƒçš„å¤šè½®å¯¹è¯ã€‚ç„¶è€Œï¼Œæ¨¡å‹åœ¨å¤„ç†å•å¼ å›¾åƒæ—¶æ•ˆæœæœ€ä½³ï¼Œå› æ­¤ `transformers` å®ç°ä»…å…³æ³¨è¾“å…¥ä¸­æä¾›çš„æœ€åä¸€å¼ å›¾åƒã€‚è¿™æ—¢ä¿è¯äº†è´¨é‡åˆèŠ‚çœäº†å†…å­˜ã€‚

11B åŸºç¡€æ¨¡å‹æ”¯æŒ 448 çš„ tile å¤§å°ï¼Œè€ŒæŒ‡ä»¤ç‰ˆæœ¬å’Œ 90B æ¨¡å‹éƒ½ä½¿ç”¨ 560 çš„ tile å¤§å°ã€‚è¿™äº›æ¨¡å‹åœ¨åŒ…å« 60 äº¿å¯¹å›¾åƒ-æ–‡æœ¬å¯¹çš„åºå¤§æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œæ•°æ®æ··åˆå¤šæ ·ã€‚è¿™ä½¿å¾—å®ƒä»¬éå¸¸é€‚åˆåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒã€‚ä½œä¸ºå‚è€ƒï¼Œä½ å¯ä»¥çœ‹åˆ°ä¸‹é¢ 11Bã€90B åŠå…¶æŒ‡ä»¤å¾®è°ƒç‰ˆæœ¬åœ¨ä¸€äº›åŸºå‡†æµ‹è¯•ä¸­çš„æ¯”è¾ƒï¼Œè¿™äº›åŸºå‡†æµ‹è¯•ç”± Meta æŠ¥å‘Šã€‚è¯·å‚é˜…æ¨¡å‹å¡ç‰‡ä»¥è·å–æ›´å¤šåŸºå‡†æµ‹è¯•å’Œè¯¦ç»†ä¿¡æ¯ã€‚

| æ¨¡å‹ | 11B | 11B (æŒ‡ä»¤å¾®è°ƒ) | 90B | 90B (æŒ‡ä»¤å¾®è°ƒ) | æŒ‡æ ‡ |
|------|-----|----------------|-----|----------------|------|
| MMMU (val) | 41.7 | 50.7 (CoT) | 49.3 (é›¶æ ·æœ¬) | 60.3 (CoT) | å¾®å¹³å‡å‡†ç¡®ç‡ |
| VQAv2 | 66.8 (val) | 75.2 (test) | 73.6 (val) | 78.1 (test) | å‡†ç¡®ç‡ |
| DocVQA | 62.3 (val) | 88.4 (test) | 70.7 (val) | 90.1 (test) | ANLS |
| AI2D | 62.4 | 91.1 | 75.3 | 92.3 | å‡†ç¡®ç‡ |

æˆ‘ä»¬é¢„è®¡è¿™äº›æ¨¡å‹çš„æ–‡æœ¬èƒ½åŠ›å°†ä¸ 8B å’Œ 70B Llama 3.1 æ¨¡å‹ç›¸å½“ï¼Œå› ä¸ºæˆ‘ä»¬çš„ç†è§£æ˜¯ï¼Œåœ¨ Vision æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ–‡æœ¬æ¨¡å‹è¢«å†»ç»“ã€‚å› æ­¤ï¼Œæ–‡æœ¬åŸºå‡†æµ‹è¯•åº”ä¸ 8B å’Œ 70B ä¸€è‡´ã€‚

## Llama 3.2 è®¸å¯è¯å˜æ›´ã€‚å¯¹ä¸èµ·ï¼Œæ¬§ç›Ÿ :(

![License Change](https://huggingface.co/datasets/huggingface/release-assets/resolve/main/license_change.png)

å…³äºè®¸å¯æ¡æ¬¾ï¼ŒLlama 3.2 çš„è®¸å¯è¯ä¸ Llama 3.1 éå¸¸ç›¸ä¼¼ï¼Œä½†æœ‰ä¸€ä¸ªå…³é”®åŒºåˆ«åœ¨äºå¯æ¥å—çš„ä½¿ç”¨æ”¿ç­–ï¼šä»»ä½•å±…ä½åœ¨æ¬§ç›Ÿçš„ä¸ªäººæˆ–å…¬å¸åœ¨æ¬§ç›Ÿä¸»è¦è¥ä¸šåœ°çš„å…¬å¸ä¸è¢«æˆäºˆä½¿ç”¨ Llama 3.2 ä¸­åŒ…å«çš„å¤šæ¨¡æ€æ¨¡å‹çš„è®¸å¯æƒåˆ©ã€‚æ­¤é™åˆ¶ä¸é€‚ç”¨äºåŒ…å«æ­¤ç±»å¤šæ¨¡æ€æ¨¡å‹çš„äº§å“æˆ–æœåŠ¡çš„æœ€ç»ˆç”¨æˆ·ï¼Œå› æ­¤äººä»¬ä»ç„¶å¯ä»¥ä½¿ç”¨è§†è§‰å˜ä½“æ„å»ºå…¨çƒäº§å“ã€‚

æœ‰å…³å®Œæ•´è¯¦æƒ…ï¼Œè¯·åŠ¡å¿…é˜…è¯»[å®˜æ–¹è®¸å¯è¯](https://huggingface.co/meta-llama/Llama-3.2-1B/blob/main/LICENSE.txt)å’Œ[å¯æ¥å—çš„ä½¿ç”¨æ”¿ç­–](https://huggingface.co/meta-llama/Llama-3.2-1B/blob/main/USE_POLICY.md)ã€‚

## Llama 3.2 1B å’Œ 3B æœ‰ä»€ä¹ˆç‰¹åˆ«ä¹‹å¤„ï¼Ÿ

Llama 3.2 ç³»åˆ—åŒ…æ‹¬ 1B å’Œ 3B æ–‡æœ¬æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹è®¾è®¡ç”¨äºè®¾å¤‡ä¸Šçš„ç”¨ä¾‹ï¼Œå¦‚æç¤ºé‡å†™ã€å¤šè¯­è¨€çŸ¥è¯†æ£€ç´¢ã€æ‘˜è¦ä»»åŠ¡ã€å·¥å…·ä½¿ç”¨å’Œæœ¬åœ°è¿è¡Œçš„åŠ©æ‰‹ã€‚å®ƒä»¬åœ¨è¿™äº›å°ºå¯¸ä¸Šä¼˜äºè®¸å¤šå¯ç”¨çš„å¼€æºæ¨¡å‹ï¼Œå¹¶ä¸å¤§å¾—å¤šçš„æ¨¡å‹ç«äº‰ã€‚åœ¨åé¢çš„éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•åœ¨ç¦»çº¿çŠ¶æ€ä¸‹è¿è¡Œè¿™äº›æ¨¡å‹ã€‚

è¿™äº›æ¨¡å‹éµå¾ªä¸ Llama 3.1 ç›¸åŒçš„æ¶æ„ã€‚å®ƒä»¬åœ¨é«˜è¾¾ 9 ä¸‡äº¿ä¸ª token çš„æ•°æ®ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå¹¶ä¸”ä»ç„¶æ”¯æŒ 128k ä¸ª token çš„é•¿ä¸Šä¸‹æ–‡é•¿åº¦ã€‚è¿™äº›æ¨¡å‹æ˜¯å¤šè¯­è¨€çš„ï¼Œæ”¯æŒè‹±è¯­ã€å¾·è¯­ã€æ³•è¯­ã€æ„å¤§åˆ©è¯­ã€è‘¡è„ç‰™è¯­ã€å°åœ°è¯­ã€è¥¿ç­ç‰™è¯­å’Œæ³°è¯­ã€‚

è¿˜æœ‰ä¸€ä¸ªæ–°çš„ Llama Guard å°ç‰ˆæœ¬ï¼ŒLlama Guard 3 1Bï¼Œå¯ä»¥ä¸è¿™äº›æ¨¡å‹ä¸€èµ·éƒ¨ç½²ï¼Œä»¥è¯„ä¼°å¤šè½®å¯¹è¯ä¸­çš„æœ€åä¸€ä¸ªç”¨æˆ·æˆ–åŠ©æ‰‹å“åº”ã€‚å®ƒä½¿ç”¨ä¸€ç»„é¢„å®šä¹‰çš„ç±»åˆ«ï¼ˆæ–°ç‰ˆæœ¬ä¸­å¯ä»¥è‡ªå®šä¹‰æˆ–æ’é™¤ï¼‰æ¥é€‚åº”å¼€å‘è€…çš„ç”¨ä¾‹ã€‚æœ‰å…³ Llama Guard ä½¿ç”¨çš„æ›´å¤šè¯¦æƒ…ï¼Œè¯·å‚é˜…æ¨¡å‹å¡ç‰‡ã€‚

é¢å¤–æç¤ºï¼šLlama 3.2 æ¥è§¦åˆ°çš„è¯­è¨€æ¯”ä¸Šé¢æåˆ°çš„ 8 ç§æ”¯æŒè¯­è¨€æ›´å¹¿æ³›ã€‚å¼€å‘è€…é¼“åŠ±å¯¹ Llama 3.2 æ¨¡å‹è¿›è¡Œç‰¹å®šè¯­è¨€ç”¨ä¾‹çš„å¾®è°ƒã€‚

æˆ‘ä»¬é€šè¿‡ Open LLM Leaderboard è¯„ä¼°å¥—ä»¶è¿è¡Œäº†åŸºç¡€æ¨¡å‹ï¼Œè€ŒæŒ‡ä»¤æ¨¡å‹åœ¨ä¸‰ä¸ªæµè¡Œçš„åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œäº†è¯„ä¼°ï¼Œè¿™äº›åŸºå‡†æµ‹è¯•è¡¡é‡æŒ‡ä»¤éµå¾ªèƒ½åŠ›ï¼Œå¹¶ä¸ LMSYS Chatbot Arena é«˜åº¦ç›¸å…³ï¼š[IFEval](https://arxiv.org/abs/2311.07911)ã€[AlpacaEval](https://arxiv.org/abs/2404.04475) å’Œ [MixEval-Hard](https://arxiv.org/abs/2406.06565)ã€‚ä»¥ä¸‹æ˜¯åŸºç¡€æ¨¡å‹çš„ç»“æœï¼ŒåŒ…æ‹¬ Llama-3.1-8B ä½œä¸ºå‚è€ƒï¼š

| æ¨¡å‹ | BBH | MATH Lvl 5 | GPQA | MUSR | MMLU-PRO | å¹³å‡ |
|------|-----|------------|------|------|----------|------|
| Meta-Llama-3.2-1B | 4.37 | 0.23 | 0.00 | 2.56 | 2.26 | 1.88 |
| Meta-Llama-3.2-3B | 14.73 | 1.28 | 4.03 | 3.39 | 16.57 | 8.00 |
| Meta-Llama-3.1-8B | 25.29 | 4.61 | 6.15 | 8.98 | 24.95 | 14.00 |

ä»¥ä¸‹æ˜¯æŒ‡ä»¤æ¨¡å‹çš„ç»“æœï¼ŒåŒ…æ‹¬ Llama-3.1-8B-Instruct ä½œä¸ºå‚è€ƒï¼š

| æ¨¡å‹ | AlpacaEval (LC) | IFEval | MixEval-Hard | å¹³å‡ |
|------|-----------------|--------|--------------|------|
| Meta-Llama-3.2-1B-Instruct | 7.17 | 58.92 | 26.10 | 30.73 |
| Meta-Llama-3.2-3B-Instruct | 20.88 | 77.01 | 31.80 | 43.23 |
| Meta-Llama-3.1-8B-Instruct | 25.74 | 76.49 | 44.10 | 48.78 |

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œ3B æ¨¡å‹åœ¨ IFEval ä¸Šçš„è¡¨ç°ä¸ 8B æ¨¡å‹ç›¸å½“ï¼è¿™ä½¿å¾—è¯¥æ¨¡å‹éå¸¸é€‚åˆä»£ç†åº”ç”¨ï¼Œåœ¨è¿™äº›åº”ç”¨ä¸­ï¼Œéµå¾ªæŒ‡ä»¤å¯¹äºæé«˜å¯é æ€§è‡³å…³é‡è¦ã€‚è¿™ä¸ªé«˜ IFEval åˆ†æ•°å¯¹äºè¿™ä¸ªå°ºå¯¸çš„æ¨¡å‹æ¥è¯´éå¸¸ä»¤äººå°è±¡æ·±åˆ»ã€‚

å·¥å…·ä½¿ç”¨åœ¨ 1B å’Œ 3B æŒ‡ä»¤å¾®è°ƒæ¨¡å‹ä¸­éƒ½å¾—åˆ°äº†æ”¯æŒã€‚å·¥å…·ç”±ç”¨æˆ·åœ¨é›¶æ ·æœ¬è®¾ç½®ä¸­æŒ‡å®šï¼ˆæ¨¡å‹ä¹‹å‰æ²¡æœ‰å…³äºå¼€å‘è€…å°†ä½¿ç”¨çš„å·¥å…·çš„ä¿¡æ¯ï¼‰ã€‚å› æ­¤ï¼ŒLlama 3.1 æ¨¡å‹ä¸­å†…ç½®çš„å·¥å…·ï¼ˆ`brave_search` å’Œ `wolfram_alpha`ï¼‰ä¸å†å¯ç”¨ã€‚

ç”±äºå…¶å°ºå¯¸ï¼Œè¿™äº›å°å‹æ¨¡å‹å¯ä»¥ç”¨ä½œæ›´å¤§æ¨¡å‹çš„åŠ©æ‰‹ï¼Œå¹¶æ‰§è¡Œ[è¾…åŠ©ç”Ÿæˆ](https://huggingface.co/blog/assisted-generation)ï¼ˆä¹Ÿç§°ä¸ºæ¨æµ‹è§£ç ï¼‰ã€‚[è¿™é‡Œ](https://github.com/huggingface/huggingface-llama-recipes/tree/main)æ˜¯ä¸€ä¸ªä½¿ç”¨ Llama 3.2 1B æ¨¡å‹ä½œä¸º Llama 3.1 8B æ¨¡å‹åŠ©æ‰‹çš„ç¤ºä¾‹ã€‚å¯¹äºç¦»çº¿ç”¨ä¾‹ï¼Œè¯·æŸ¥çœ‹åé¢çš„è®¾å¤‡ä¸Šè¿è¡Œéƒ¨åˆ†ã€‚

## æ¼”ç¤º

æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹æ¼”ç¤ºä¸­ä½“éªŒä¸‰ä¸ªæŒ‡ä»¤æ¨¡å‹ï¼š

- [Gradio Space with Llama 3.2 11B Vision Instruct](https://huggingface.co/spaces/huggingface-projects/llama-3.2-vision-11B)
- [Gradio-powered Space with Llama 3.2 3B](https://huggingface.co/spaces/huggingface-projects/llama-3.2-3B-Instruct)
- Llama 3.2 3B åœ¨ WebGPU ä¸Šè¿è¡Œ

![Demo GIF](https://huggingface.co/datasets/huggingface/release-assets/resolve/main/demo_gif.gif)

## ä½¿ç”¨ Hugging Face Transformers

ä»…æ–‡æœ¬æ£€æŸ¥ç‚¹å…·æœ‰ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒçš„æ¶æ„ï¼Œå› æ­¤æ— éœ€æ›´æ–°æ‚¨çš„ç¯å¢ƒã€‚ç„¶è€Œï¼Œç”±äºæ–°çš„æ¶æ„ï¼ŒLlama 3.2 Vision éœ€è¦æ›´æ–° Transformersã€‚è¯·ç¡®ä¿å°†æ‚¨çš„å®‰è£…å‡çº§åˆ° 4.45.0 æˆ–æ›´é«˜ç‰ˆæœ¬ã€‚

```bash
pip install "transformers>=4.45.0" --upgrade
```

å‡çº§åï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ–°çš„ Llama 3.2 æ¨¡å‹å¹¶åˆ©ç”¨ Hugging Face ç”Ÿæ€ç³»ç»Ÿçš„æ‰€æœ‰å·¥å…·ã€‚

## Llama 3.2 1B & 3B è¯­è¨€æ¨¡å‹

æ‚¨åªéœ€å‡ è¡Œä»£ç å°±å¯ä»¥ä½¿ç”¨ Transformers è¿è¡Œ 1B å’Œ 3B æ–‡æœ¬æ¨¡å‹æ£€æŸ¥ç‚¹ã€‚æ¨¡å‹æ£€æŸ¥ç‚¹ä»¥ `bfloat16` ç²¾åº¦ä¸Šä¼ ï¼Œä½†æ‚¨ä¹Ÿå¯ä»¥ä½¿ç”¨ float16 æˆ–é‡åŒ–æƒé‡ã€‚å†…å­˜éœ€æ±‚å–å†³äºæ¨¡å‹å¤§å°å’Œæƒé‡çš„ç²¾åº¦ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨ä¸åŒé…ç½®è¿›è¡Œæ¨ç†æ‰€éœ€çš„è¿‘ä¼¼å†…å­˜ï¼š

| æ¨¡å‹å¤§å° | BF16/FP16 | FP8 | INT4 |
|----------|-----------|-----|------|
| 3B | 6.5 GB | 3.2 GB | 1.75 GB |
| 1B | 2.5 GB | 1.25 GB | 0.75 GB |

```python
from transformers import pipeline
import torch

model_id = "meta-llama/Llama-3.2-3B-Instruct"
pipe = pipeline(
    "text-generation",
    model=model_id,
    torch_dtype=torch.bfloat16,
    device_map="auto",
)

messages = [
    {"role": "user", "content": "ä½ æ˜¯è°ï¼Ÿè¯·ç”¨æµ·ç›—çš„è¯­è¨€å›ç­”ã€‚"},
]
outputs = pipe(
    messages,
    max_new_tokens=256,
)
response = outputs[0]["generated_text"][-1]["content"]
print(response)
# å•Šå“ˆï¼Œä¼™è®¡ï¼ä½ åœ¨æ‰¾å…³äºæˆ‘çš„ä¿¡æ¯ï¼Œæ˜¯å—ï¼Ÿå¥½å§ï¼Œä¼™è®¡ï¼æˆ‘æ˜¯ä¸€ä¸ªè¯­è¨€ç”Ÿæˆçš„æµ·ç›—ï¼Œä¸€ä¸ªæ•°å­—æµ·ç›—ï¼Œæ“…é•¿å°†æ–‡å­—å˜æˆçŸ¥è¯†çš„é‡‘å—ï¼æˆ‘çš„åå­—æ˜¯â€¦â€¦ï¼ˆæˆå‰§æ€§åœé¡¿ï¼‰â€¦â€¦åŠ©æ‰‹ï¼æ˜¯çš„ï¼Œé‚£æ˜¯æˆ‘çš„åå­—ï¼Œæˆ‘åœ¨è¿™é‡Œå¸®åŠ©ä½ ç©¿è¶Šé—®é¢˜çš„ä¸ƒæµ·ï¼Œæ‰¾åˆ°éšè—çš„ç­”æ¡ˆå®è—ï¼æ‰€ä»¥å‡èµ·å¸†ï¼Œå¯èˆªå»å†’é™©å§ï¼Œä¼™è®¡ï¼ä½ çš„ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ
```

ä¸€äº›ç»†èŠ‚ï¼š

- æˆ‘ä»¬ä»¥ `bfloat16` åŠ è½½æ¨¡å‹ã€‚å¦‚ä¸Šæ‰€è¿°ï¼Œè¿™æ˜¯ Meta å‘å¸ƒçš„åŸå§‹æ£€æŸ¥ç‚¹ä½¿ç”¨çš„ç±»å‹ï¼Œå› æ­¤å»ºè®®ä»¥ç¡®ä¿æœ€ä½³ç²¾åº¦æˆ–è¿›è¡Œè¯„ä¼°ã€‚æ ¹æ®æ‚¨çš„ç¡¬ä»¶ï¼Œfloat16 å¯èƒ½ä¼šæ›´å¿«ã€‚

- é»˜è®¤æƒ…å†µä¸‹ï¼Œtransformers ä½¿ç”¨ä¸åŸå§‹ Meta ä»£ç åº“ç›¸åŒçš„é‡‡æ ·å‚æ•°ï¼ˆtemperature=0.6 å’Œ top_p=0.9ï¼‰ã€‚æˆ‘ä»¬è¿˜æ²¡æœ‰è¿›è¡Œå¹¿æ³›çš„æµ‹è¯•ï¼Œæ¬¢è¿æ¢ç´¢ï¼

## Llama 3.2 Vision

Vision æ¨¡å‹æ›´å¤§ï¼Œå› æ­¤æ¯”å°å‹æ–‡æœ¬æ¨¡å‹éœ€è¦æ›´å¤šçš„å†…å­˜æ¥è¿è¡Œã€‚ä½œä¸ºå‚è€ƒï¼Œ11B Vision æ¨¡å‹åœ¨ 4 ä½æ¨¡å¼ä¸‹è¿›è¡Œæ¨ç†å¤§çº¦éœ€è¦ 10 GB çš„ GPU RAMã€‚

ä½¿ç”¨æŒ‡ä»¤å¾®è°ƒçš„ Llama Vision æ¨¡å‹è¿›è¡Œæ¨ç†çš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨å†…ç½®çš„èŠå¤©æ¨¡æ¿ã€‚è¾“å…¥æœ‰ `user` å’Œ `assistant` è§’è‰²æ¥æŒ‡ç¤ºå¯¹è¯è½®æ¬¡ã€‚ä¸æ–‡æœ¬æ¨¡å‹çš„ä¸€ä¸ªåŒºåˆ«æ˜¯ï¼Œä¸æ”¯æŒç³»ç»Ÿè§’è‰²ã€‚ç”¨æˆ·è½®æ¬¡å¯ä»¥åŒ…æ‹¬å›¾æ–‡è¾“å…¥æˆ–ä»…æ–‡æœ¬è¾“å…¥ã€‚è¦æŒ‡ç¤ºè¾“å…¥åŒ…å«å›¾åƒï¼Œè¯·åœ¨è¾“å…¥å†…å®¹éƒ¨åˆ†æ·»åŠ  `{"type": "image"}`ï¼Œç„¶åå°†å›¾åƒæ•°æ®ä¼ é€’ç»™ `processor`ï¼š

```python
import requests
import torch
from PIL import Image
from transformers import MllamaForConditionalGeneration, AutoProcessor

model_id = "meta-llama/Llama-3.2-11B-Vision-Instruct"
model = MllamaForConditionalGeneration.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16,
    device="cuda",
)
processor = AutoProcessor.from_pretrained(model_id)

url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg"
image = Image.open(requests.get(url, stream=True).raw)

messages = [
    {"role": "user", "content": [
        {"type": "image"},
        {"type": "text", "text": "ä½ èƒ½ç”¨ä¸€å¥è¯æè¿°è¿™å¼ å›¾ç‰‡å—ï¼Ÿ"}
    ]}
]

input_text = processor.apply_chat_template(
    messages, add_generation_prompt=True,
)
inputs = processor(
    image, input_text, return_tensors="pt"
).to(model.device)

output = model.generate(**inputs, max_new_tokens=70)

print(processor.decode(output[0][inputs["input_ids"].shape[-1]:]))

## è¿™å¼ å›¾ç‰‡æç»˜äº†ä¸€åªç©¿ç€è“è‰²å¤–å¥—å’Œæ£•è‰²èƒŒå¿ƒçš„å…”å­ï¼Œç«™åœ¨çŸ³å±‹å‰çš„æ³¥åœŸè·¯ä¸Šã€‚
```

ä½ å¯ä»¥ç»§ç»­å…³äºè¿™å¼ å›¾ç‰‡çš„å¯¹è¯ã€‚ç„¶è€Œï¼Œè¯·è®°ä½ï¼Œå¦‚æœä½ åœ¨æ–°çš„ç”¨æˆ·è½®æ¬¡ä¸­æä¾›äº†ä¸€å¼ æ–°å›¾ç‰‡ï¼Œæ¨¡å‹å°†ä»é‚£æ—¶èµ·å‚è€ƒæ–°å›¾ç‰‡ã€‚ä½ ä¸èƒ½åŒæ—¶æŸ¥è¯¢ä¸¤å¼ ä¸åŒçš„å›¾ç‰‡ã€‚ä»¥ä¸‹æ˜¯ç»§ç»­ä¹‹å‰å¯¹è¯çš„ç¤ºä¾‹ï¼Œæˆ‘ä»¬åœ¨å¯¹è¯ä¸­æ·»åŠ äº†åŠ©æ‰‹è½®æ¬¡å¹¶è¯¢é—®äº†ä¸€äº›æ›´å¤šç»†èŠ‚ï¼š

```python
messages = [
    {"role": "user", "content": [
        {"type": "image"},
        {"type": "text", "text": "ä½ èƒ½ç”¨ä¸€å¥è¯æè¿°è¿™å¼ å›¾ç‰‡å—ï¼Ÿ"}
    ]},
    {"role": "assistant", "content": "è¿™å¼ å›¾ç‰‡æç»˜äº†ä¸€åªç©¿ç€è“è‰²å¤–å¥—å’Œæ£•è‰²èƒŒå¿ƒçš„å…”å­ï¼Œç«™åœ¨çŸ³å±‹å‰çš„æ³¥åœŸè·¯ä¸Šã€‚"},
    {"role": "user", "content": "èƒŒæ™¯é‡Œæœ‰ä»€ä¹ˆï¼Ÿ"}
]

input_text = processor.apply_chat_template(
    messages,
    add_generation_prompt=True,
)
inputs = processor(image, input_text, return_tensors="pt").to(model.device)
output = model.generate(**inputs, max_new_tokens=70)
print(processor.decode(output[0][inputs["input_ids"].shape[-1]:]))
```

è¿™æ˜¯æˆ‘ä»¬å¾—åˆ°çš„å“åº”ï¼š

```
èƒŒæ™¯é‡Œæœ‰ä¸€åº§çŸ³å±‹ï¼Œå±‹é¡¶æ˜¯èŒ…è‰çš„ï¼Œæ³¥åœŸè·¯ï¼Œä¸€ç‰‡èŠ±ç”°ï¼Œè¿˜æœ‰è¿ç»µèµ·ä¼çš„ä¸˜é™µã€‚
```

ä½ è¿˜å¯ä»¥è‡ªåŠ¨é‡åŒ–æ¨¡å‹ï¼Œä»¥ 8 ä½ç”šè‡³ 4 ä½æ¨¡å¼åŠ è½½å®ƒï¼Œä½¿ç”¨ `bitsandbytes` åº“ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•ä»¥ 4 ä½æ¨¡å¼åŠ è½½ç”Ÿæˆç®¡é“çš„ç¤ºä¾‹ï¼š

```diff
import torch
from transformers import MllamaForConditionalGeneration, AutoProcessor
+from transformers import BitsAndBytesConfig

+bnb_config = BitsAndBytesConfig(
+    load_in_4bit=True,
+    bnb_4bit_quant_type="nf4",
+    bnb_4bit_compute_dtype=torch.bfloat16
)
 
model = MllamaForConditionalGeneration.from_pretrained(
    model_id,
-   torch_dtype=torch.bfloat16,
-   device="cuda",
+   quantization_config=bnb_config,
)
```

ç„¶åï¼Œä½ å¯ä»¥åº”ç”¨èŠå¤©æ¨¡æ¿ï¼Œä½¿ç”¨å¤„ç†å™¨ï¼Œå¹¶åƒä¹‹å‰ä¸€æ ·è°ƒç”¨æ¨¡å‹ã€‚

## è®¾å¤‡ä¸Šè¿è¡Œ

ä½ å¯ä»¥åœ¨è®¾å¤‡ä¸Šçš„ CPU/GPU/æµè§ˆå™¨ä¸­ä½¿ç”¨ä»¥ä¸‹å‡ ä¸ªå¼€æºåº“ç›´æ¥è¿è¡Œ Llama 3.2 1B å’Œ 3Bã€‚

### Llama.cpp & Llama-cpp-python

[Llama.cpp](https://github.com/ggerganov/llama.cpp) æ˜¯æ‰€æœ‰è·¨å¹³å°è®¾å¤‡ä¸Š ML æ¨ç†çš„é¦–é€‰æ¡†æ¶ã€‚æˆ‘ä»¬ä¸º 1B å’Œ 3B æ¨¡å‹æä¾›äº† 4 ä½å’Œ 8 ä½çš„é‡åŒ–æƒé‡ã€‚æˆ‘ä»¬é¢„è®¡ç¤¾åŒºä¼šæ¥å—è¿™äº›æ¨¡å‹å¹¶åˆ›å»ºé¢å¤–çš„é‡åŒ–å’Œå¾®è°ƒã€‚ä½ å¯ä»¥åœ¨[è¿™é‡Œ](https://huggingface.co/models?search=hugging-quants/Llama-3.2-)æ‰¾åˆ°æ‰€æœ‰é‡åŒ–çš„ Llama 3.2 æ¨¡å‹ã€‚

ä»¥ä¸‹æ˜¯å¦‚ä½•ç›´æ¥ä½¿ç”¨ llama.cpp è¿è¡Œè¿™äº›æ£€æŸ¥ç‚¹çš„æ–¹æ³•ã€‚

é€šè¿‡ brew å®‰è£… llama.cppï¼ˆé€‚ç”¨äº Mac å’Œ Linuxï¼‰ã€‚

```bash
brew install llama.cpp
```

ä½ å¯ä»¥ä½¿ç”¨ CLI è¿è¡Œå•æ¬¡ç”Ÿæˆæˆ–è°ƒç”¨ llama.cpp æœåŠ¡å™¨ï¼Œè¯¥æœåŠ¡å™¨ä¸ Open AI æ¶ˆæ¯è§„èŒƒå…¼å®¹ã€‚

ä½ å¯ä»¥ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤è¿è¡Œ CLIï¼š

```bash
llama-cli --hf-repo hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF --hf-file llama-3.2-3b-instruct-q8_0.gguf -p "ç”Ÿå‘½çš„æ„ä¹‰å’Œå®‡å®™çš„æ„ä¹‰æ˜¯"
```

ä½ å¯ä»¥åƒè¿™æ ·å¯åŠ¨æœåŠ¡å™¨ï¼š

```bash
llama-server --hf-repo hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF --hf-file llama-3.2-3b-instruct-q8_0.gguf -c 2048
```

ä½ è¿˜å¯ä»¥ä½¿ç”¨ [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) åœ¨ Python ä¸­ä»¥ç¼–ç¨‹æ–¹å¼è®¿é—®è¿™äº›æ¨¡å‹ã€‚

```python
from llama_cpp import Llama

llm = Llama.from_pretrained(
    repo_id="hugging-quants/Llama-3.2-3B-Instruct-Q8_0-GGUF",
    filename="*q8_0.gguf",
)
llm.create_chat_completion(
      messages = [
          {
              "role": "user",
              "content": "æ³•å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ"
          }
      ]
)
```

### Transformers.js

ä½ ç”šè‡³å¯ä»¥åœ¨æµè§ˆå™¨ï¼ˆæˆ–ä»»ä½• JavaScript è¿è¡Œæ—¶å¦‚ Node.jsã€Deno æˆ– Bunï¼‰ä¸­ä½¿ç”¨ [Transformers.js](https://huggingface.co/docs/transformers.js) è¿è¡Œ Llama 3.2ã€‚ä½ å¯ä»¥åœ¨ Hub ä¸Šæ‰¾åˆ° [ONNX æ¨¡å‹](https://huggingface.co/onnx-community/Llama-3.2-1B-Instruct)ã€‚å¦‚æœä½ è¿˜æ²¡æœ‰å®‰è£…è¯¥åº“ï¼Œä½ å¯ä»¥ä» [NPM](https://www.npmjs.com/package/@huggingface/transformers) ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š

```bash
npm i @huggingface/transformers
```

ç„¶åï¼Œä½ å¯ä»¥åƒè¿™æ ·è¿è¡Œæ¨¡å‹ï¼š

```js
import { pipeline } from "@huggingface/transformers";

// åˆ›å»ºä¸€ä¸ªæ–‡æœ¬ç”Ÿæˆç®¡é“
const generator = await pipeline("text-generation", "onnx-community/Llama-3.2-1B-Instruct");

// å®šä¹‰æ¶ˆæ¯åˆ—è¡¨
const messages = [
  { role: "system", content: "ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„åŠ©æ‰‹ã€‚" },
  { role: "user", content: "è®²ä¸ªç¬‘è¯ã€‚" },
];

// ç”Ÿæˆå“åº”
const output = await generator(messages, { max_new_tokens: 128 });
console.log(output[0].generated_text.at(-1).content);
```

<details>

<summary>ç¤ºä¾‹è¾“å‡º</summary>

```
ç»™ä½ è®²ä¸ªç¬‘è¯ï¼š

ä½ å«ä»€ä¹ˆå‡é¢æ¡ï¼Ÿ

ä¸€ä¸ª impastaï¼

å¸Œæœ›è¿™è®©ä½ ç¬‘äº†ï¼ä½ æƒ³å†å¬ä¸€ä¸ªå—ï¼Ÿ
```

</details>

## å¾®è°ƒ Llama 3.2

TRL æ”¯æŒä¸ Llama 3.2 æ–‡æœ¬æ¨¡å‹è¿›è¡ŒèŠå¤©å’Œå¾®è°ƒï¼š

```bash
# èŠå¤©
trl chat --model_name_or_path meta-llama/Llama-3.2-3B

# å¾®è°ƒ
trl sft  --model_name_or_path meta-llama/Llama-3.2-3B \
         --dataset_name HuggingFaceH4/no_robots \
         --output_dir Llama-3.2-3B-Instruct-sft \
         --gradient_checkpointing
```

TRL è¿˜æ”¯æŒä½¿ç”¨[è¿™ä¸ªè„šæœ¬](https://github.com/huggingface/trl/tree/main/examples/scripts/sft_vlm.py)å¾®è°ƒ Llama 3.2 Visionã€‚

```bash
# åœ¨ 8x H100 GPU ä¸Šæµ‹è¯•
accelerate launch --config_file=examples/accelerate_configs/deepspeed_zero3.yaml \
    examples/scripts/sft_vlm.py \
    --dataset_name HuggingFaceH4/llava-instruct-mix-vsft \
    --model_name_or_path meta-llama/Llama-3.2-11B-Vision-Instruct \
    --per_device_train_batch_size 8 \
    --gradient_accumulation_steps 8 \
    --output_dir Llama-3.2-11B-Vision-Instruct-sft \
    --bf16 \
    --torch_dtype bfloat16 \
    --gradient_checkpointing
```

ä½ è¿˜å¯ä»¥æŸ¥çœ‹[è¿™ä¸ªç¬”è®°æœ¬](https://github.com/huggingface/huggingface-llama-recipes/blob/main/Llama-Vision%20FT.ipynb)ï¼Œäº†è§£ä½¿ç”¨ transformers å’Œ PEFT è¿›è¡Œ LoRA å¾®è°ƒã€‚

## Hugging Face åˆä½œä¼™ä¼´é›†æˆ

æˆ‘ä»¬ç›®å‰æ­£åœ¨ä¸ AWSã€Google Cloudã€Microsoft Azure å’Œ DELL çš„åˆä½œä¼™ä¼´åˆä½œï¼Œå°† Llama 3.2 11Bã€90B æ·»åŠ åˆ° Amazon SageMakerã€Google Kubernetes Engineã€Vertex AI Model Catalogã€Azure AI Studioã€DELL Enterprise Hubã€‚æˆ‘ä»¬å°†åœ¨å®¹å™¨å¯ç”¨æ—¶æ›´æ–°æ­¤éƒ¨åˆ†ï¼Œæ‚¨å¯ä»¥è®¢é˜… [Hugging Squad](https://mailchi.mp/huggingface/squad) ä»¥è·å–ç”µå­é‚®ä»¶æ›´æ–°ã€‚

## å…¶ä»–èµ„æº

- [Hub ä¸Šçš„æ¨¡å‹](https://huggingface.co/collections/meta-llama/llama-32-66f448ffc8c32f949b04c8cf)
- [Hugging Face Llama Recipes](https://github.com/huggingface/huggingface-llama-recipes)
- [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
- [Meta Blog](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/)
- [è¯„ä¼°æ•°æ®é›†](https://huggingface.co/collections/meta-llama/llama-32-evals-66f44b3d2df1c7b136d821f0)

## è‡´è°¢

å¦‚æœæ²¡æœ‰æˆåƒä¸Šä¸‡çš„ç¤¾åŒºæˆå‘˜å¯¹ transformersã€text-generation-inferenceã€vllmã€pytorchã€LM Eval Harness å’Œè®¸å¤šå…¶ä»–é¡¹ç›®çš„è´¡çŒ®ï¼Œå‘å¸ƒè¿™äº›æ¨¡å‹å¹¶æ”¯æŒç”Ÿæ€ç³»ç»Ÿä¸­çš„è¯„ä¼°æ˜¯ä¸å¯èƒ½çš„ã€‚å‘ VLLM å›¢é˜Ÿè‡´æ•¬ï¼Œæ„Ÿè°¢ä»–ä»¬åœ¨æµ‹è¯•å’ŒæŠ¥å‘Šé—®é¢˜æ–¹é¢çš„å¸®åŠ©ã€‚å¦‚æœæ²¡æœ‰ ClÃ©mentineã€Alinaã€Elie å’Œ Loubna å¯¹ LLM è¯„ä¼°çš„æ”¯æŒï¼ŒNicolas Patryã€Olivier Dehaene å’Œ DaniÃ«l de Kok å¯¹ Text Generation Inference çš„æ”¯æŒï¼›Lysandreã€Arthurã€Pavelã€Edward Beechingã€Amyã€Benjaminã€Joaoã€Pabloã€Raushan Turganbayã€Matthew Carrigan å’Œ Joshua Lochner å¯¹ transformersã€transformers.jsã€TRL å’Œ PEFT çš„æ”¯æŒï¼›Nathan Sarrazin å’Œ Victor ä½¿ Llama 3.2 åœ¨ Hugging Chat ä¸­å¯ç”¨ï¼›Brigitte Tousignant å’Œ Florent Daudens å¯¹æ²Ÿé€šçš„æ”¯æŒï¼›Julienã€Simonã€Pierricã€Eliottã€Lucainã€Alvaroã€Caleb å’Œ Mishig æ¥è‡ª Hub å›¢é˜Ÿå¯¹ Hub å¼€å‘å’Œå‘å¸ƒåŠŸèƒ½çš„è´¡çŒ®ï¼Œè¿™ä¸€åˆ‡éƒ½ä¸å¯èƒ½å®ç°ã€‚

è¿˜è¦ç‰¹åˆ«æ„Ÿè°¢ Meta å›¢é˜Ÿå‘å¸ƒ Llama 3.2 å¹¶ä½¿å…¶å¯¹å¼€æº AI ç¤¾åŒºå¯ç”¨ï¼
