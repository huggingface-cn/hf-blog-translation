---
title: "StackLLaMA": ç”¨ RLHF è®­ç»ƒ LLaMA çš„æ‰‹æŠŠæ‰‹æ•™ç¨‹ 
thumbnail: /blog/assets/138_stackllama/thumbnail.png
authors:
- user: edbeeching
- user: kashif
- user: ybelkada
- user: lewtun
- user: lvwerra
- user: nazneen
- user: natolambert
--- 

<!--Authors ä½œè€…ä¿¡æ¯-->

# "StackLLaMA": ç”¨ RLHF è®­ç»ƒ LLaMA çš„æ‰‹æŠŠæ‰‹æ•™ç¨‹

è¯­è¨€æ¨¡å‹å¦‚ [ChatGPT](https://openai.com/blog/chatgpt)ï¼Œ [GPT-4](https://openai.com/research/gpt-4)ï¼Œ [Glaude](https://www.anthropic.com/index/introducing-claude) ä¹‹å¼ºå¤§ï¼Œ å› ä¸ºå®ƒä»¬é‡‡ç”¨äº†*åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ * (Reinforcement Learning from Human Feedbackï¼Œ RLHF) æ¥ä½¿ä¹‹æ›´ç¬¦åˆæˆ‘ä»¬çš„ä½¿ç”¨åœºæ™¯ã€‚

æœ¬åšå®¢æ—¨åœ¨å±•ç¤ºç”¨ RLHF è®­ç»ƒä¸€ä¸ª [LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai) æ¨¡å‹ï¼Œ ä»¥å›ç­” [Stack Exchange](https://stackexchange.com/) ä¸Šçš„é—®é¢˜ã€‚ å…·ä½“çš„ï¼Œ æ˜¯

- æœ‰ç›‘ç£çš„å¾®è°ƒ (Supervised Fine-tuningï¼Œ SFT)ã€‚
- å¥–åŠ± / åå¥½å»ºæ¨¡ (Reward / preference modelingï¼Œ RM)ã€‚
- åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹  (RLHF)ã€‚

![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/stackllama/instructGPT.png)
æ‘˜è‡ª InstructGPT è®ºæ–‡ï¼Œ Ouyang, Long, et al. "Training language models to follow instructions with human feedback." arXiv preprint arXiv:2203.02155 (2022).

ç»“åˆäº†ä¸Šè¿°æ–¹æ³•ï¼Œ æˆ‘ä»¬å‘å¸ƒäº† StackLLaMA æ¨¡å‹ï¼Œ è¯¥æ¨¡å‹åœ¨ [ğŸ¤— Hub](https://huggingface.co/trl-lib/llama-se-rl-peft) ä¸Šå¼€æº (çœ‹ [Meta çš„åŸå§‹ LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) )ï¼Œ ä»¥åŠæ•´ä¸ª [è®­ç»ƒçš„æµç¨‹](https://huggingface.co/docs/trl/index) ä»¥åŠé›†æˆåˆ°äº† Hugging Face TRL åº“ä¸­ ã€‚ä½ å¯ä»¥é€šè¿‡ä¸‹é¢çš„ [demo](https://huggingface.co/spaces/trl-lib/stack-llama) æ¥å“é‰´ä¸€ä¸‹è¯¥æ¨¡å‹ã€‚

<script
	type="module"
	src="https://gradio.s3-us-west-2.amazonaws.com/3.23.0/gradio.js"></script>

<gradio-app src="https://trl-lib-stack-llama.hf.space"></gradio-app>

## LLaMA æ¨¡å‹

åœ¨å®è·µ RLHF æ—¶ï¼Œ é€‰å–ä¸€ä¸ªåˆé€‚çš„æ¨¡å‹å¾ˆé‡è¦: RLHF åªæ˜¯ä¸€ä¸ªè®©æ¨¡å‹æ»¡è¶³æˆ‘ä»¬äº¤äº’å½¢å¼çš„éœ€æ±‚çš„å¾®è°ƒè¿‡ç¨‹ ã€‚æ‰€ä»¥æˆ‘ä»¬é€‰å–äº†æœ€è¿‘ä¸Šçº¿çš„ [LLaMA](https://arxiv.org/abs/2302.13971) æ¨¡å‹ã€‚ LLaMA æ¨¡å‹æ˜¯ Mata AI æœ€è¿‘æ¨å‡ºçš„å¤§è¯­è¨€æ¨¡å‹ã€‚ å…¶å‚æ•°é‡å¤§å°æ¶µç›– 7B åˆ° 65Bï¼Œ ä»¥åŠè®­ç»ƒåœ¨ 1T å’Œ 1.4T çš„ token ä¸Šï¼Œ è¿™è®©å…¶å¾ˆå®ç”¨ã€‚ æˆ‘ä»¬è¿™é‡Œé‡‡ç”¨ 7B çš„æ¨¡å‹ã€‚ (è¯·å¡«å†™ Meta AI çš„è¿™ä»½ [è¡¨](https://docs.google.com/forms/d/e/1FAIpQLSfqNECQnMkycAp2jP4Z9TFX0cGR4uf7b_fBxjY_OjhJILlKGA/viewform) æ¥ä¸‹è½½æ¨¡å‹)ã€‚

## Stack Exchange æ•°æ®é›†

æ”¶é›†äººç±»çš„åé¦ˆæ•°æ®é›†æ˜¯å¾ˆå¤æ‚ä¸”æ˜‚è´µçš„åŠ³åŠ¨ã€‚ ä¸ºäº†åšåˆ°è¿™ä¸ªï¼Œ å¹¶ä¸”è¿˜èƒ½ä¿è¯æ¨¡å‹çš„æœ‰æ•ˆæ€§ï¼Œ æˆ‘ä»¬ä½¿ç”¨ [StackExchange æ•°æ®é›†](https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences)ã€‚ è¯¥æ•°æ®é›†æ¶µç›–äº† StackExchange å¹³å°ä¸Šçš„é—®é¢˜å’Œç­”æ¡ˆ (åŒ…å« StackOverflow çš„ code ç­‰è¯é¢˜ä¸‹çš„)ã€‚ è¿™å¯¹æœ¬é—®é¢˜æ˜¯å¾ˆåˆé€‚çš„ï¼Œ å› ä¸ºå…¶åŒ…å«äº†æ¯ä¸ªç­”æ¡ˆçš„èµå’Œè¸©çš„æ•°ã€‚é‡

æˆ‘ä»¬éµä» [Askell et al. 2021](https://arxiv.org/abs/2112.00861) ä¸­çš„æ–¹æ³•ï¼Œ ç»™æ¯ä¸ªç­”æ¡ˆèµ‹åˆ†ï¼Œ

```
score = log2 (1 + upvotes) rounded to the nearest integer, plus 1 if the questioner accepted the answer (we assign a score of âˆ’1 if the number of upvotes is negative).
```

å¯¹å¥–åŠ±æ¨¡å‹ï¼Œ æˆ‘ä»¬å°†çœ‹åˆ°ï¼Œ æ€»æ˜¯æ¯ä¸ªé—®é¢˜éœ€è¦ä¸¤ä¸ªç­”æ¡ˆå¯¹æ¯”ã€‚ æœ‰äº›é—®é¢˜æœ‰å¾ˆå¤šç­”æ¡ˆï¼Œ å¯ä»¥äº§ç”Ÿå¾ˆå¤šå¯¹ï¼Œ æˆ‘ä»¬åªå–åä¸ªä»¥é™åˆ¶æ¯ä¸ªé—®é¢˜çš„æ•°æ®é‡ã€‚ æœ€åï¼Œ æˆ‘ä»¬æŠŠæ ¼å¼ä» HTML è½¬åŒ–åˆ° Markdown ä»¥æé«˜è¾“å‡ºçš„å¯è¯»æ€§ã€‚ ä½ å¯ä»¥çœ‹åˆ°æ•°æ®é›†å’Œå¤„ç†è¿‡ç¨‹çš„[ç¬”è®°æœ¬](https://huggingface.co/datasets/lvwerra/stack-exchange-pairedã€‚)

## é«˜æ•ˆè®­ç»ƒç­–ç•¥

å³ä½¿æ˜¯æœ€å° LLaMA æ¨¡å‹çš„è®­ç»ƒï¼Œ éƒ½éœ€è¦å¤§é‡å†…å­˜ã€‚ ä¼°ç®—ä¸€ä¸‹: ä»¥ bf16 åŠç²¾åº¦ï¼Œ æ¯ä¸ªå‚æ•°ç”¨ 2 ä¸ªå­—èŠ‚ (ä»¥ fp32 ç²¾åº¦å››å­—èŠ‚çš„æ ‡å‡†)ï¼Œ è®­ç»ƒæ—¶éœ€è¦ 8 ä¸ªå­—èŠ‚(ä¾‹å¦‚ï¼Œ Adam ä¼˜åŒ–å™¨ï¼Œ å‚è§ Tramsformers çš„ [æ€§èƒ½æ–‡æ¡£](https://huggingface.co/docs/transformers/perf_train_gpu_one#optimizer) )ã€‚ æ‰€ä»¥ï¼Œ 7B å‚æ•°é‡çš„æ¨¡å‹å°†ç”¨ (2+8) * 7B = 70 GB çš„å†…å­˜ï¼Œ å¹¶ä¸”è¿˜å¯èƒ½æ›´å¤š (è®¡ç®—è¯¸å¦‚æ³¨æ„åŠ›åˆ†æ•°çš„ä¸­é—´å€¼)ã€‚ æ‰€ä»¥ä¸æ–¹ä¾¿åœ¨ä¸€å¼  80GB çš„ A100 ä¸Šè®­ç»ƒä¹‹ã€‚ ä½ éœ€è¦ä¸€äº›æŠ€å·§ï¼Œ æ¯”å¦‚æ›´é«˜æ•ˆçš„åŠç²¾åº¦è®­ç»ƒçš„ä¼˜åŒ–å™¨ï¼Œ ä»¥å‹ç¼©ç‚¹å†…å­˜ï¼Œ ä½†æº¢å‡ºæ˜¯è¿Ÿæ—©ã€‚çš„

å¦å¤–çš„å¯èƒ½æ˜¯ *å‚æ•°é«˜æ•ˆçš„å¾®è°ƒ* (Parameter-Efficient Fine-Tuning, PEFT) æŠ€æœ¯ï¼Œ æ¯”å¦‚ [peft]() åº“ï¼Œ å®ƒå¯ä»¥å¯¹ 8-bit <!--ä¸æ‡‚--> æ¨¡å‹åš *ä½ç§©ä¼˜åŒ–* (Low-Rank Adaptationï¼Œ LoRAã€‚)

![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/stackllama/lora-animated.gif)
çº¿æ€§å±‚çš„ä½ç§©ä¼˜åŒ–: æ–°å‚æ•°(æ©™è‰²) è¢«åŠ åœ¨å›ºå®šçš„å‚æ•°(è“è‰²)è¾¹ï¼Œ æœ€åç¼–ç çš„éšè—å€¼ç›¸ã€‚åŠ 

ä»¥ 8bit åŠ è½½æ¨¡å‹ä¼šå¤§å¹…é™ä½å†…å­˜å ç”¨ï¼Œ å› ä¸ºæ¯ä¸ªå‚æ•°åªè¦ä¸€å­—èŠ‚ (æ¯”å¦‚ 7B LLaMA æ˜¯ 7GB å†…å­˜)ã€‚ ä¸ç›´æ¥è®­ç»ƒåŸå§‹æ¨¡å‹ä¸åŒï¼Œ LoRA åœ¨ç‰¹å®šå±‚ (ä¸€èˆ¬æ˜¯æ³¨æ„åŠ›å±‚) æ·»åŠ å°‘é‡æ–°å‚æ•°ï¼Œ å¤§å¹…é™ä½äº†éœ€è¦è®­ç»ƒçš„å‚ã€‚æ•°

æ­¤æƒ…æ­¤æ™¯ï¼Œ ä¸€ä¸ªè¡¡é‡æ ‡å‡†æ˜¯ 1B çš„å‚æ•°åœ¨æ•´ä¸ªå¾®è°ƒè¿‡ç¨‹ä¸­å  ~1.2-1.4GB (å’Œå…·ä½“ batch sizeï¼Œ åºåˆ—é•¿åº¦æœ‰å…³)ã€‚ åœ¨å‚è€ƒçš„åšå®¢ä¸­å…·ä½“è®¨è®ºäº†ï¼Œ è¿™æå¤§åœ°æé«˜äº†ä½æˆæœ¬ä¸‹ï¼Œ å¯å¾®è°ƒæ¨¡å‹çš„å¤§å° (åœ¨ ä¸€å¼  A100 ä¸Šå¯åˆ° 50-60B çš„å‚æ•°é‡ã€‚)

è¿™äº›æŠ€æœ¯èƒ½è®©å¾®è°ƒå¤§æ¨¡å‹çš„è¿‡ç¨‹ï¼Œ è·‘åœ¨ç”¨æˆ·ç«¯å’Œ Google Colabã€‚ æœ‰äº›å€¼å¾—ä¸€æçš„ç»“æœ: `facebook/opt-6.7b` (åœ¨ float16 ç²¾åº¦ä¸‹ 13GB) å’Œ `openai/whisper-large` è·‘åœ¨ Google Colab (15GB æ˜¾å­˜)ä¸Šã€‚ æ¬²äº†è§£ `peft` çš„ä½¿ç”¨ï¼Œ è¯·å‚è§ [github ä»“åº“](https://github.com/huggingface/peft) æˆ–è€…ä¹‹å‰çš„[åšå®¢ä»‹ç»](https://huggingface.co/blog/trl-peft): åœ¨å®¢æˆ·ç«¯è®­ç»ƒ 20B å‚æ•°é‡çš„æ¨¡ã€‚å‹

ç°åœ¨æˆ‘ä»¬èƒ½åœ¨ä¸€å¼  GPU ä¸Šå¾®è°ƒå¾ˆå¤§çš„æ¨¡å‹äº†ï¼Œ ä½†è®­ç»ƒè¿˜æ˜¯ä¼šå¾ˆæ…¢ã€‚ æ­¤æƒ…æ­¤æ™¯ï¼Œ æœ€ç®€å•çš„ç­–ç•¥ä¾¿æ˜¯å¹¶è¡ŒåŒ–: æŠŠä¸€ä¸ªè®­ç»ƒåŒæ—¶æ”¾åˆ°ä¸åŒçš„ GPU ä¸Šï¼Œ å„ GPU æ¥å—ä¸åŒçš„ batchï¼Œ ä»¥æ­¤å¹¶è¡ŒåŒ–å‘å‰ä¼ æ’­å’Œå‘åä¼ æ’­ï¼Œ åŠ é€ŸGPUçš„æ•°é‡å€ã€‚ 

![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/stackllama/chapter10_ddp.png)

æˆ‘ä»¬ç”¨ `trainsformers.Trainer` æˆ– `accelerate`ï¼Œ å…¶å‡æ”¯æŒæ•°æ®å¹¶è¡ŒåŒ–ï¼Œ å¹¶åªéœ€æ³¨æ„è°ƒç”¨ `torchrun` æˆ–è€… `accelerate launch` è„šæœ¬æ—¶çš„å‚æ•°ã€‚ æ¯”å¦‚ä»¥ä¸‹å°±æ˜¯åœ¨ä¸€ä¸ª 8 æ˜¾å¡çš„æœºå™¨ä¸Šåˆ†åˆ«ç”¨ `accelerate launch` å’Œ `torchrun`çš„æ–¹ã€‚æ³•

```bash
accelerate launch --multi_gpu --num_machines 1  --num_processes 8 my_accelerate_script.py

torchrun --nnodes 1  --nproc_per_node 8 my_torch_script.py
```

## æœ‰ç›‘ç£çš„å¾®è°ƒ

åœ¨è®­ç»ƒå¥–åŠ±æ¨¡å‹å’Œç”¨ RLHF ä¹‹å‰ï¼Œ æ¨¡å‹è‹¥æ˜¯èƒ½åœ¨æˆ‘ä»¬æ„Ÿå…´è¶£çš„æ–¹é¢è¡¨ç°å¥½ï¼Œ æ˜¯æœ‰å¸®åŠ©çš„ã€‚ åœ¨æ­¤æƒ…æ™¯ï¼Œ æˆ‘ä»¬æƒ³è¦å…¶èƒ½å›ç­”é—®é¢˜ï¼Œ è€Œå…¶ä»–æ—¶å€™ï¼Œ æˆ‘ä»¬å¯èƒ½å®ƒèƒ½å¬æŒ‡ä»¤(è¿™æ—¶å¯¹æŒ‡ä»¤æ‰§è¡Œçš„å¾®è°ƒæ˜¯ç†æƒ³çš„)ã€‚ å®ç°è¿™ä¸ªæœ€ç®€å•çš„æ–¹æ³•ä¾¿æ˜¯é¢å‘è¯¥è¯­è¨€ä»»åŠ¡ï¼Œ ç”¨è¯¥ä»»åŠ¡å’Œé¢†åŸŸçš„æ–‡æœ¬ï¼Œ ç»§ç»­è®­ç»ƒã€‚ [StackExchange æ•°æ®é›†]() å« 10M çš„æŒ‡ä»¤é‡ï¼Œ æ‰€ä»¥æˆ‘ä»¬èƒ½ç”¨å…¶å­é›†å¾ˆå®¹æ˜“åœ°è®­ã€‚ç»ƒ

åœ¨ç”¨ RLHF ä¹‹å‰çš„æ¨¡å‹å¾®è°ƒæ²¡æœ‰ç‰¹åˆ«çš„ï¼Œ å°±æ˜¯ä¸€èˆ¬çš„é¢å‘è¯­è¨€ä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒã€‚ ä¸ºäº†é«˜æ•ˆåˆ©ç”¨æ•°æ®ï¼Œ æˆ‘ä»¬é‡‡ç”¨äº†ç§°ä¹‹ä¸º *æ‰“åŒ…* çš„æŠ€æœ¯: ä¸ batch ä¸­çš„æ¯ä¸ªæ ·æœ¬å‡ç”±å•ä¸€æ–‡æœ¬ç»„æˆï¼Œ æœ€ååŸºäºæœ€é•¿çš„æ–‡æœ¬æ¥ padding (å¡«å……)ï¼Œ æˆ‘ä»¬æŠŠå¾ˆå¤šæ–‡æœ¬æ‹¼æ¥èµ·æ¥ï¼Œ ç”¨ EOS token æ¥éš”å¼€ï¼Œ ç„¶ååˆ†å‰²æˆä¸€äº› chunk (åˆ‡å—) æ¥åšæˆ batchï¼Œ é¿å… paddinã€‚g

![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/stackllama/chapter10_preprocessing-clm.png)

è¯¥æ–¹æ³•å¤§å¤§æé«˜äº†æ•ˆç‡ï¼Œ å› ä¸ºæ¨¡å‹è¾“å…¥çš„æ‰€æœ‰ token éƒ½å¯¹ loss æœ‰æ‰€è®­ç»ƒï¼Œ è€Œé padding ä½œä¸ºæ©ç è¢«ä¸¢å¼ƒäº†ã€‚ å¦‚æœä½ æ²¡æœ‰è¶³å¤Ÿæ•°æ®ï¼Œ å¹¶ä¸”æ‹…å¿ƒéšæ„åœ°åˆ†å¼€ token ä¼šå¤±å»ä¸Šä¸‹æ–‡è¯­ä¹‰ï¼Œ ä½ ä¹Ÿå¯ä»¥ç”¨ä¼ ç»Ÿçš„æ•°æ®åŠ è½½ã€‚å™¨

`ConstantLengthDataset` è§£å†³äº†*æ‰“åŒ…*æŠ€æœ¯ï¼Œ å¹¶ä¸”æˆ‘ä»¬èƒ½åœ¨ç”¨ `peft` åŠ è½½æ¨¡å‹åç”¨ `Trainer`ã€‚ é¦–å…ˆï¼Œ æˆ‘ä»¬ç”¨ `int8` åŠ è½½æ¨¡å‹ï¼Œ å‡†å¤‡è®­ç»ƒï¼Œ ç„¶ååŠ å…¥ `LoRA` å¾®è°ƒã€‚å™¨

```python
# load model in 8bit
model = AutoModelForCausalLM.from_pretrained(
        args.model_path,
        load_in_8bit=True,
        device_map={"": Accelerator().local_process_index}
    )
model = prepare_model_for_int8_training(model)

# add LoRA to model
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    bias="none",
    task_type="CAUSAL_LM",
)

model = get_peft_model(model, config)
```

æˆ‘ä»¬æ ¹æ®ç›¸åº”çš„è¯­è¨€ä»»åŠ¡ï¼Œ å¯¹æ¨¡å‹è®­ç»ƒå‡ åƒä¸ª step (æ­¥)ï¼Œ å¹¶ä¿å­˜æ¨¡å‹ã€‚ ç”±äºæˆ‘ä»¬å°†ä¼šæœ‰å…¶ä»–å¾®è°ƒæ¨¡å‹çš„ç›®çš„ï¼Œ æˆ‘ä»¬å°† LoRA çš„å¾®è°ƒå™¨æƒé‡åˆå¹¶åˆ°åŸæ¨¡å‹ã€‚ä¸­

**å£°æ˜**: å› ä¸º LLaMA çš„è®¸å¯è¯è§„å®šï¼Œ æˆ‘ä»¬åªèƒ½å‘å¸ƒå¾®è°ƒå™¨çš„æƒé‡ï¼Œ <!--æ²¡å¿…è¦ç¿»è¯‘-->ï¼Œ ä½ éœ€è¦å¡« Meta AI çš„[è¡¨æ ¼]()æ¥è·å–æ¨¡å‹ï¼Œ å¦‚ä½•ç”¨è¿™ä¸ª[è„šæœ¬](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/convert_llama_weights_to_hf.py)æ¥è½¬æˆ ğŸ¤— Transformers æ ¼å¼ã€‚ æ³¨æ„ ğŸ¤— Transformers åº”è¯¥ä»æºç å®‰è£…ï¼Œ æˆ–è€… `v4.28` ç‰ˆã€‚æœ¬

ç°åœ¨æˆ‘ä»¬å·²ç»å¾®è°ƒå¥½äº†æ¨¡å‹ï¼Œ å¯ä»¥è®­ç»ƒå¥–åŠ±æ¨¡å‹ã€‚äº†

## å¥–åŠ±æ¨¡å‹å’Œäººç±»åå¥½

åŸåˆ™ä¸Šï¼Œ æˆ‘ä»¬å¯ä»¥ç›´æ¥ç”¨äººç±»æ ‡æ³¨æ¥å¯¹æ¨¡å‹åš RLHF å¾®ã€‚è°ƒ

ç„¶è€Œï¼Œ è¿™å°†éœ€è¦æˆ‘ä»¬ç»™äººç±»å‘é€ä¸€äº›æ ·æœ¬ï¼Œ åœ¨æ¯è½®ä¼˜åŒ–åè®¡åˆ†ã€‚ è¿™æ˜¯è´µä¸”æ…¢çš„ï¼Œ å› ä¸ºæ”¶æ•›éœ€è¦çš„è®­ç»ƒæ ·æœ¬é‡å¤§ï¼Œ è€Œäººç±»é˜…è¯»å’Œæ ‡æ³¨çš„é€Ÿåº¦æœ‰ã€‚é™

ä¸€ä¸ªå¥½çš„ç­–ç•¥ä¾¿æ˜¯ï¼Œ åœ¨ RLHF ä¹‹å‰ç”¨äººç±»æ ‡æ³¨é›†æ¥è®­ç»ƒä¸€ä¸ªå¥–åŠ±æ¨¡å‹ã€‚ å¥–åŠ±æ¨¡å‹çš„ç›®çš„æ˜¯æ¨¡æ‹Ÿäººç±»å¯¹æ–‡æœ¬çš„æ‰“åˆ†ã€‚ æ„å»ºå¥–åŠ±æ¨¡å‹æœ‰è®¸å¤šèƒ½ç”¨çš„ç­–ç•¥: æœ€ç›´æ¥çš„ä¾¿æ˜¯é¢„æµ‹æ ‡æ³¨ (æ¯”å¦‚æ ¹æ®å¥½ä¸åï¼Œ è¾“å‡ºæ¯”åˆ†æˆ–è€…å¸ƒå°”å€¼)ã€‚ æœ€ä½³å®è·µæ˜¯ï¼Œ é¢„æµ‹ç»“æœçš„æ’åºï¼Œ å³å¯¹æ¯ä¸ª prompt (è¾“å…¥æ–‡æœ¬) å¯¹åº”çš„ä¸¤ä¸ªç»“æœ $(y_k, y_j)$ï¼Œ æ¨¡å‹é¢„æµ‹äººç±»æ ‡æ³¨çš„æ¯”åˆ†å“ªä¸ªæ›´é«˜ã€‚ <!--æ‰€ä»¥ç©¶ç«Ÿè®²äº†ä»€ä¹ˆ....-->

æˆ–è€…è¡¨ç¤ºä¸º loss (æŸå¤±) å‡½æ•°

$$
 \mbox{loss}(\theta) = - E_{(x, y_j, y_k)~D} [ \mbox{log}( \sigma( r_\theta (x, y_j) - r_\theta(x, y_k)) ) ]
$$

å…¶ä¸­ $r$ æ˜¯æ¨¡å‹å¯¹å¯èƒ½çš„æ ‡æ³¨$y_j$çš„é¢„æµ‹åˆ†ã€‚æ•°

åœ¨ StackExchange æ•°æ®é›†ä¸Šï¼Œ æˆ‘ä»¬èƒ½å¾—åˆ°ä¸¤ä¸ªç­”æ¡ˆçš„å—æ¬¢è¿ç¨‹åº¦ã€‚ æœ‰äº†è¿™ä¸ªä¿¡æ¯å’Œä¸Šé¢çš„ lossï¼Œ æˆ‘ä»¬å°±èƒ½è‡ªå®šä¹‰ loss æ¥æ”¹ `transformers.Trainer` ã€‚äº†

```python

class RewardTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False):
        rewards_j = model(input_ids=inputs["input_ids_j"],  attention_mask=inputs["attention_mask_j"])[0]
        rewards_k = model(input_ids=inputs["input_ids_k"], attention_mask=inputs["attention_mask_k"])[0]
        loss = -nn.functional.logsigmoid(rewards_j - rewards_k).mean()
        if return_outputs:
            return loss, {"rewards_j": rewards_j, "rewards_k": rewards_k}
        return loss
```

æˆ‘ä»¬ç”¨æ•°æ®é›†ä¸­çš„ 100000 å¯¹ï¼Œ å¹¶åœ¨ 50000 å¯¹ä¸Šè¯„ä¼°ã€‚ åœ¨æ¯”è¾ƒå°çš„ batch sizeï¼Œ ä¸º 4 ä¸‹ï¼Œ æˆ‘ä»¬ç”¨ LoRA çš„ `peft` å¾®è°ƒå™¨æ¥è®­ç»ƒ LLaMA æ¨¡å‹ï¼Œ åœ¨ bf16 ç²¾åº¦ä¸‹ç”¨ Adam ä¼˜åŒ–å™¨ã€‚ æˆ‘ä»¬çš„ LoRA è®¾ç½®ï¼Œæ˜¯

```python
peft_config = LoraConfig(
    task_type=TaskType.SEQ_CLS,
    inference_mode=False,
    r=8,
    lora_alpha=32,
    lora_dropout=0.1,
)
```

è®­ç»ƒç”¨[Weights & Biases](https://wandb.ai/krasul/huggingface/runs/wmd8rvq6?workspace=user-krasul)æ¥è®°æ—¥å¿—ï¼Œ å¹¶åœ¨ ğŸ¤— è®­ç»ƒé›†ç¾¤ä¸Šï¼Œ ç”¨8å¡A-100ï¼Œ è¦æ•°å°æ—¶ï¼Œ æœ€åå‡†ç¡®ç‡ä¸º **67%**ã€‚ å°½ç®¡çœ‹ä¸Šå»å¯èƒ½ä½äº†ï¼Œ ä½†æƒ³æƒ³è¿™ä¸ªä»»åŠ¡çš„éš¾ã€‚åº¦

å¦‚ä¸‹æ–‡è¦ç»†è¯´çš„ï¼Œ è®­ç»ƒç»“æœå°†ä½œä¸ºå›ºå®šå‚æ•°ï¼Œ ä»¥ä¾›ä¸‹æ¸¸ä½¿ã€‚ç”¨

## åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ 

ç°åœ¨æˆ‘ä»¬æ‰‹å¤´æœ‰äº†å¾®è°ƒçš„è¯­è¨€æ¨¡å‹å’Œå¥–åŠ±æ¨¡å‹ï¼Œ å¯ä»¥å¼€å§‹ RLHF äº†: è¿™å¤§è‡´æ˜¯ä¸‰æ­¥

1. ç”Ÿäº§å¯¹ prompt (è¾“å…¥æ–‡æœ¬)çš„åé¦ˆã€‚
2. ç”¨å¥–åŠ±æ¨¡å‹æ¥å¯¹åé¦ˆè¯„åˆ†ã€‚
3. å¯¹è¯„åˆ†ï¼Œ è¿›è¡Œä¸€è½®ç­–ç•¥ä¼˜åŒ–çš„å¼ºåŒ–å­¦ä¹ ã€‚

![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/stackllama/trl_loop.png)

åœ¨è¢« token åŒ–å¹¶è¾“å…¥å¥–åŠ±æ¨¡å‹é’±ï¼Œ æé—®å’Œå›ç­”çš„ prompt æ¨¡ç‰ˆå¦‚ä¸‹
```
Question: <Query>
Answer: <Response>
```

åœ¨æœ‰ç›‘ç£è®­ç»ƒ (SFT)ï¼Œ å¥–åŠ±æ¨¡å‹è®­ç»ƒ (RM) å’Œ RLHF çš„é˜¶æ®µéƒ½ç”¨æ”¹æ¨¡ç‰ˆã€‚

ç”¨ RL è®­ç»ƒè¯­è¨€æ¨¡å‹å‡ºç°å¸¸è§çš„é—®é¢˜æ˜¯ï¼Œ æ¨¡å‹å¯èƒ½å­¦ä¼šèƒ¡è¯´å…«é“ä»¥ç³Šå¼„å¥–åŠ±æ¨¡å‹ï¼Œ åè€…å¯èƒ½ç»™é«˜åˆ†ã€‚ ä¸ºäº†æƒè¡¡ï¼Œ æˆ‘ä»¬å¯¹å¥–åŠ±å¢åŠ æƒ©ç½š: ç•™ä¸€ä»½æ²¡æœ‰è®­ç»ƒçš„æ¨¡å‹ï¼Œ å¦‚ä½•æ¯”è¾ƒä¸¤è€…è¾“å‡ºçš„ KL æ•£åº¦

$$
\mbox{R}(x, y) = \mbox{r}(x, y) - \beta \mbox{KL}(x,y)
$$

å…¶ä¸­ $r$ æ˜¯å¥–åŠ±æ¨¡å‹çš„ç»“æœï¼Œ $\mbox{KL}(x,y)$ æ˜¯å½“å‰æ¨¡å‹å’Œå¯¹æ¯”æ¨¡å‹çš„ KL æ•£åº¦å·®ã€‚

å†æä¸€éï¼Œ æˆ‘ä»¬ç”¨ `peft` æ¥å®ç°å†…å­˜é«˜æ•ˆçš„è®­ç»ƒï¼Œ å…¶å¯¹ RLHF é˜¶æ®µæä¾›äº†ä¼˜åŠ¿ã€‚ è¿™é‡Œå‚è€ƒçš„æ¨¡å‹å’Œè®­ç»ƒçš„æ¨¡å‹ç”¨åŒä¸€ä¸ªåŸºåº•ï¼Œ ä¹Ÿå°±æ˜¯æœ‰ç›‘ç£è®­ç»ƒ (SFT) çš„ç»“æœï¼Œ å®ƒæ˜¯ç”¨ 8-bit æ¥åŠ è½½ï¼Œ å¹¶ä¸”è‡ªå§‹è‡ªç»ˆæ˜¯å›ºå®šçš„ã€‚ æˆ‘ä»¬ä»…ç”¨ PPO æ–¹æ³•ä¼˜åŒ–æœ€ç»ˆæ¨¡å‹çš„ LoRA æƒé‡ï¼Œ åŒæ—¶å…¨éƒ¨å…±äº«ä¸€ä¸ªåŸºåº•æ¨¡å‹ã€‚

```python
for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):
    question_tensors = batch["input_ids"]
        
    # sample from the policy and generate responses
    response_tensors = ppo_trainer.generate(
        question_tensors,
        return_prompt=False,
        length_sampler=output_length_sampler,
        **generation_kwargs,
    )
    batch["response"] = tokenizer.batch_decode(response_tensors, skip_special_tokens=True)

    # Compute sentiment score
    texts = [q + r for q, r in zip(batch["query"], batch["response"])]
    pipe_outputs = sentiment_pipe(texts, **sent_kwargs)
    rewards = [torch.tensor(output[0]["score"] - script_args.reward_baseline) for output in pipe_outputs]

    # Run PPO step
    stats = ppo_trainer.step(question_tensors, response_tensors, rewards)
    # Log stats to WandB
    ppo_trainer.log_stats(stats, batch, rewards)
```

æˆ‘ä»¬ç”¨ ğŸ¤— é›†ç¾¤ï¼Œ åœ¨ 3x8 A100-80GB çš„æœºå™¨ä¸Šè®­ç»ƒäº† 20hï¼Œ ä½†ä¸€ä¸ªå·®ä¸å¤šçš„ç»“æœå¾ˆå¿« (å¤§æ¦‚ï¼Œ åœ¨ 8 A100-80GB ä¸Šè®­ç»ƒ 20h)ã€‚ æ‰€æœ‰çš„è®­ç»ƒè¿‡ç¨‹éƒ½åœ¨ [Weight & Biases](https://wandb.ai/lvwerra/trl/runs/ie2h4q8p) ä¸Šæ‰¾åˆ°ã€‚

![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/stackllama/wandb_reward.png)
æ¯ä¸ª batch çš„å¥–åŠ±ï¼Œ å¯¹æ¯æ­¥çš„è®­ç»ƒï¼Œ åœ¨ ~1000 æ­¥æ—¶æ¨¡å‹çš„æ•ˆæœæœ€å¥½ã€‚

æ‰€ä»¥æ¨¡å‹è®­å¥½äº†èƒ½å¹²å•¥å˜? æˆ‘ä»¬æ‹­ç›®ä»¥å¾…!

![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/stackllama/llama_prompt.png)

å°½ç®¡æˆ‘ä»¬ä¸è¯¥å¤ªç›¸ä¿¡å…¶ç»“æœï¼Œ è‡³å°‘ç›®å‰ã€‚ ä½†ç»“æœå·²ç»å¾ˆå¥½äº†ï¼Œ ç”šè‡³é™„ä¸Šäº† Google é“¾æ¥ã€‚ æˆ‘ä»¬æ¥çœ‹çœ‹è®­ç»ƒæ—¶çš„æŒ‘æˆ˜ã€‚

## æŒ‘æˆ˜ï¼Œ ä¸ç¨³å®šå’Œçªç ´å£

ç”¨ RL è®­ç»ƒ LLM (Large Language Modelsï¼Œ å¤§è¯­è¨€æ¨¡å‹) ä¸æ€»æ˜¯ä¸€å¸†é£é¡ºçš„ï¼Œ ä½ çœ‹åˆ°çš„æœ¬æ–‡ä¹Ÿæ˜¯ç»å†æ— æ•°å®éªŒï¼Œ æ— æ•°å¤±è´¥å’Œæ— æ•°è°ƒå‚çš„ã€‚ å³ä¾¿å¦‚æ­¤ï¼Œ è¯¥æ¨¡å‹ä¹Ÿä¸èƒ½è¯´å˜ç°å®Œç¾ã€‚ è¿™å„¿ï¼Œ æˆ‘ä»¬åˆ†äº«ä¸€äº›é‡åˆ°çš„è§‚å¯Ÿå’Œé—®é¢˜ã€‚

### å¥–åŠ±æ›´é«˜ä»£è¡¨æ›´å¥½è¡¨ç°?

![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/stackllama/logs_high_reward.png)
å¤©å‘ï¼Œ è¿™ä¸ªå®éªŒè‚¯å®šè¡¨ç°å¾ˆå¥½! çœ‹å¥–åŠ±çš„æ›²çº¿å¤šç”œå•Š!

åœ¨ RL ä¸­ï¼Œ ä¸€èˆ¬è€Œè¨€ï¼Œ å¥–åŠ±è¶Šé«˜è¶Šå¥½ã€‚ åœ¨ RLHF ä¸­ï¼Œ æˆ‘ä»¬ç”¨äº†ä¸€ä¸ªå¥–åŠ±æ¨¡å‹ï¼Œ å®ƒä¸å®Œç¾ï¼Œ æ‰€ä»¥ç•™ç»™äº† PPO ç®—æ³•æ¡æ¼çš„æœºä¼šã€‚ è¿™èƒ½å¯¼è‡´å¥–åŠ±çªç„¶ä¸Šå‡ï¼Œ ç„¶è€Œå½“æ£€æŸ¥æ–‡æœ¬ç»“æœæ—¶ï¼Œ å´å……æ–¥äº†å­—ç¬¦ "\`\`\`"ï¼Œ å› ä¸ºå¥–åŠ±æ¨¡å‹å¯¹å«æœ‰ä»£ç  stack exchange çš„ç­”æ¡ˆæ›´ä¿¡ä»»ã€‚ å¹¸è¿çš„æ˜¯ï¼Œ è¯¥é—®é¢˜ç¢°åˆ°çš„å¾ˆå°‘ï¼Œ åº”è¯¥æ˜¯é‡‡å–çš„ KL æ•£åº¦çš„æƒ©ç½šé¡¹èµ·åˆ°äº†ä½œç”¨ã€‚

### KL æ•£åº¦æ€»æ˜¯æ­£çš„?

å¦‚æˆ‘ä»¬å‰é¢æ‰€æåˆ°çš„ï¼Œ ä¸€ä¸ª KL æƒ©ç½šé¡¹è¢«ç”¨æ¥ä¿è¯è®­ç»ƒåçš„åˆ†å¸ƒå’ŒåŸå§‹åˆ†å¸ƒæ¥è¿‘ã€‚ ä¸€èˆ¬åœ°, KL æ•£åº¦æ¥åº¦é‡ä¸¤ä¸ªåˆ†å¸ƒçš„ç›¸ä¼¼ç¨‹åº¦ï¼Œ å¹¶ä¸”æ€»æ˜¯æ­£çš„ã€‚ ç„¶è€Œï¼Œ åœ¨ `trl` æˆ‘ä»¬ç”¨äº†ä¸€ä¸ª KL çš„è¿‘ä¼¼ï¼Œ æœŸæœ›å€¼å’ŒçœŸçš„ KL æ•£åº¦ç›¸åŒã€‚

$$
KL_{pen} (x, y) = \mbox{log} (\pi_\phi^\mbox{RL}(y | x) / \pi^{\mbox{SFT}}(y|x))
$$

æ˜¾ç„¶ï¼Œ å½“è®­ç»ƒä¸­ä¸€ä¸ª token æ¯”åŸå§‹æ¨¡å‹æ¦‚ç‡ä½ï¼Œ è¿™ä¼šå¯¼è‡´ KL æ•£åº¦ä¸ºè´Ÿï¼Œ åˆé€‚çš„å–æ ·å’Œå¹³å‡æ€»èƒ½å¾—åˆ°æ­£çš„ã€‚ ä½†æ˜¯ä¸€äº›é‡‡æ ·çš„ç”Ÿæˆç­–ç•¥å¯¼è‡´äº†ä¸åŒ€ç§°çš„é‡‡æ ·ã€‚ æ¯”å¦‚ï¼Œ å½“ç”Ÿæˆè¢« padding çš„åºåˆ— batch æ—¶å’Œå½“è®¾ç½® EOS token è¢«å‹ç¼©çš„æœ€å°é•¿åº¦æ˜¯ï¼Œ æ¨¡å‹ä¼šæœ‰å¾ˆå¤§/å¾ˆå°çš„æ¦‚ç‡åˆ°è´Ÿ KL æ•£åº¦çš„ tokenã€‚ åŒæ—¶ PPO ç®—æ³•æ˜¯é¢å‘å¥–åŠ±ä¼˜åŒ–çš„ï¼Œ æ¨¡å‹å°±ä¼šè¿½é€è´Ÿçš„æƒ©ç½šï¼Œ å¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚

![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/stackllama/logs_neg_kl.png)

å¯¹ç”Ÿæˆå’Œé‡‡æ ·ï¼Œ ä½ éœ€è¦ç‰¹åˆ«å°å¿ƒã€‚ æˆ‘ä»¬å»ºè®®ä¸€å¼€å§‹ç”¨æœ€ç®€å•çš„æ–¹å¼ï¼Œ å¦‚ä½•åœ¨é€æ¸å¤æ‚ã€‚

### ä»»ç„¶å­˜åœ¨çš„é—®é¢˜

ä»»ç„¶æœ‰å¾ˆå¤šé—®é¢˜æˆ‘ä»¬ä¸æ‡‚ï¼Œ æ¯”å¦‚ä¸‹é¢ï¼Œ loss é—´æ–­åœ°è·³è·ƒï¼Œ å¯¼è‡´ä¹‹åçš„ä¸ç¨³å®š

![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/stackllama/logs_loss_spikes.png)

ä¸€æ—¦æˆ‘ä»¬è§£å†³äº†è¿™äº›é—®é¢˜ï¼Œ æˆ‘ä»¬å°±ä¼šä¸Šä¼ å˜åŒ–åˆ° `trl` ä¸Šï¼Œ ä»¥ä¿è¯ç¤¾åŒºå—ç›Šã€‚

## æ€»ç»“

åœ¨æœ¬åšå®¢ï¼Œ æˆ‘ä»¬èµ°è¿‡äº† RLHF è®­ç»ƒçš„æ•´ä¸ªæµç¨‹ï¼Œ ä»å‡†å¤‡äººç±»æ ‡æ³¨çš„æ•°æ®é›†å¼€å§‹ï¼Œ è°ƒæ•´è¯­è¨€æ¨¡å‹åˆ°ç‰¹å®šé¢†åŸŸï¼Œ è®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œ å¹¶æœ€ç»ˆç”¨ RL è®­ç»ƒä¸€ä¸ªæ¨¡å‹ã€‚

é€šè¿‡ä½¿ç”¨ `peft`ï¼Œ ä»»ä½•äººéƒ½èƒ½åœ¨ä¸€å¼  GPU ä¸Šè·‘æˆ‘ä»¬çš„å®éªŒ! å¦‚æœè®­ç»ƒæ…¢äº†ï¼Œ å¯ä»¥ç”¨æ•°æ®å¹¶è¡ŒåŒ–çš„æ–¹æ³•ï¼Œ ä¸éœ€è¦æ”¹ä»»ä½•ä»£ç ï¼Œ æˆ–è€…ç”¨å¤šå¼  GPU å¹¶è¡Œæé«˜è®­ç»ƒé€Ÿåº¦ã€‚

å¯¹å®é™…åº”ç”¨ï¼Œ è¿™ä»…ä»…æ˜¯ç¬¬ä¸€æ­¥! ä¸€æ—¦ä½ æœ‰äº†æ¨¡å‹ï¼Œ ä½ å°±è¦å’Œå…¶ä»–æ¨¡å‹æ¯”è¾ƒä¼˜åŠ£ã€‚ è¿™ä¸ªå¯ä»¥ç”¨ä¸€ä¸ªé¢å‘ä¸åŒæ¨¡å‹çš„æ’åç”Ÿæˆåšåˆ°ï¼Œ å’Œæˆ‘ä»¬è®­ç»ƒå¥–åŠ±æ•°æ®é›†ç±»ä¼¼ã€‚

ä¸€æ—¦ä½ åŠ å…¥äº†è¯„ä¼°çš„æ­¥éª¤ï¼Œ å¥½ç©çš„å°±å¼€å§‹äº†: ä½ å¯ä»¥åœ¨åŸæ•°æ®é›†ä¸Šåå¤ç‚¼ä¸¹ï¼Œ ä¹Ÿå¯ä»¥å¢åŠ æ•°æ®é›†æˆ–è€…å¯¹åŸæ•°æ®é›†æçº¯ã€‚ å¦å¤–ï¼Œ ä½ å¯ä»¥å¯¹å¥–åŠ±æ¨¡å‹å’Œç”Ÿæˆè¯•ä¸åŒå¤§å°å’Œç»“æ„çš„æ¨¡å‹ï¼Œ è¿™éœ€è¦æ—¶é—´ã€‚

æˆ‘ä»¬åœ¨ç§¯ææé«˜ TRL ä»¥ä¿è¯ RLHF çš„æ¯ä¸€æ­¥éƒ½å¯è§ï¼Œ å¹¶ä¸”ååˆ†æ¿€åŠ¨èƒ½çœ‹åˆ°äººä»¬ç”¨å®ƒæ¥æ„å»ºçš„ä¸œè¥¿ã€‚ å¦‚æœä½ æƒ³æœ‰æ‰€è´¡çŒ®ï¼Œ æ¬¢è¿çœ‹æˆ‘ä»¬çš„ [Github Issue](https://github.com/lvwerra/trl/issues)ã€‚

## Citation
```
@misc {beeching2023stackllama,
    author       = { Edward Beeching and
                     Younes Belkada and
                     Kashif Rasul and
                     Lewis Tunstall and
                     Leandro von Werra and
                     Nazneen Rajani and
                     Nathan Lambert
                   },
    title        = { StackLLaMA: An RL Fine-tuned LLaMA Model for Stack Exchange Question and Answering },
    year         = 2023,
    url          = { https://huggingface.co/blog/stackllama },
    doi          = { 10.57967/hf/0513 },
    publisher    = { Hugging Face Blog }
}
```

## æ„Ÿè°¢

æˆ‘ä»¬æ„Ÿè°¢ Philipp Schmid åˆ†äº«äº†ä»–å¯¹æ–‡æœ¬ç”Ÿæˆç»å¦™çš„ [demo](https://huggingface.co/spaces/philschmid/igel-playground), æˆ‘ä»¬çš„ demo ä¹Ÿæ˜¯åŸºäºä»–çš„ã€‚æˆ‘ä»¬ä¹Ÿæ„Ÿè°¢ Omar Sanseviero å’Œ Louis Castricato å¯¹æˆ‘ä»¬åšå®¢çš„è‰ç¨¿æä¾›å®è´µè¯¦å°½çš„åé¦ˆã€‚

`è¯‘è€…: å¼ å¥‡`
